<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="IE科协">
        <link rel="canonical" href="https://ie.rtfd.io/tensorflow2/basics/">
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>基础知识 - IE科协</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/custom.css?t=202108070318" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight-10.5.0-lightfair.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="../../js/highlight-10.5.0.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
		<script>
window.MathJax = {
    tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        autoload: {
            color: [],
            colorV2: ['color']
        },
        packages: {'[+]': ['noerrors']}
    },
    svg: {
        fontCache: 'global'
    },
    options: {
        ignoreHtmlClass: 'tex2jax_ignore',
        processHtmlClass: 'tex2jax_process'
    },
    loader: {
        load: ['[tex]/noerrors']
    }
};
		</script>
		<script type="text/javascript" id="MathJax-script" defer src="https://cdn.bootcdn.net/ajax/libs/mathjax/3.2.0/es5/tex-svg.min.js"></script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">IE科协</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">首页</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">PyTorch <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../pytorch/install/" class="dropdown-item">安装</a>
</li>
                                    
<li>
    <a href="../../pytorch/basics/" class="dropdown-item">基础知识</a>
</li>
                                    
<li>
    <a href="../../pytorch/cnn/" class="dropdown-item">图像数据建模：CNN</a>
</li>
                                    
<li>
    <a href="../../pytorch/rnn/" class="dropdown-item">序列数据建模：RNN</a>
</li>
                                    
<li>
    <a href="../../pytorch/mlp/" class="dropdown-item">向量数据建模：MLP</a>
</li>
                                    
<li>
    <a href="../../pytorch/datasets-and-dataloaders/" class="dropdown-item">数据加载和处理</a>
</li>
                                    
<li>
    <a href="../../pytorch/optimization/" class="dropdown-item">优化模型参数</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">TensorFlow2 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../getting-started/" class="dropdown-item">安装</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">基础知识</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">NumPy <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../numpy/multidim-array/" class="dropdown-item">ndarray 多维数组</a>
</li>
                                    
<li>
    <a href="../../numpy/multidim-array-creation-method/" class="dropdown-item">ndarray 多维数组创建方法</a>
</li>
                                    
<li>
    <a href="../../numpy/array-element-operation-method/" class="dropdown-item">数组元素的索引、切片、改变形状等操作方法</a>
</li>
                                    
<li>
    <a href="../../numpy/array-operation-function/" class="dropdown-item">数组运算函数的使用方法</a>
</li>
                                    
<li>
    <a href="../../numpy/random/" class="dropdown-item">随机数生成函数</a>
</li>
                                    
<li>
    <a href="../../numpy/file-operation/" class="dropdown-item">NumPy 数据文件的读写操作</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">seaborn <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../seaborn/seaborn/" class="dropdown-item">seaborn用法和实验</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">工作手册 <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../manual/edit/" class="dropdown-item">编辑页面</a>
</li>
                                    
<li>
    <a href="../../manual/upd/" class="dropdown-item">发布更新</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                            <li class="nav-item">
                                <a rel="prev" href="../getting-started/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../../numpy/multidim-array/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#_1" class="nav-link">基础知识</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#_2" class="nav-link">张量</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_3" class="nav-link">自动求导</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#_4" class="nav-link">一元函数求导</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#_5" class="nav-link">多元函数求偏导</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_6" class="nav-link">线性回归</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="_1">基础知识</h1>
<h2 id="_2">张量</h2>
<p>TensorFlow 使用 <strong>张量</strong> （Tensor）作为数据的基本单位。TensorFlow 的张量在概念上等同于多维数组，我们可以使用它来描述数学中的标量（0 维数组）、向量（1 维数组）、矩阵（2 维数组）等各种量，示例如下：</p>
<pre><code class="language-python"># 定义一个随机数（标量）
random_float = tf.random.uniform(shape=())

# 定义一个有2个元素的零向量
zero_vector = tf.zeros(shape=(2))

# 定义两个2×2的常量矩阵
A = tf.constant([[1., 2.], [3., 4.]])
B = tf.constant([[5., 6.], [7., 8.]])
</code></pre>
<p>可以通过张量的<code>shape</code> 、 <code>dtype</code>分别查看张量的形状和数据类型：</p>
<pre><code class="language-python"># 查看矩阵A的形状、类型和值
print(A.shape)      # 输出(2, 2)，即矩阵的长和宽均为2
print(A.dtype)      # 输出&lt;dtype: 'float32'&gt;
print(A.numpy())    # 输出[[1. 2.]
                    #      [3. 4.]]
</code></pre>
<p>我们可以使用tensorflow中的<strong>操作</strong>对已有的张量进行运算：</p>
<pre><code class="language-python">C = tf.add(A, B)    # 计算矩阵A和B的和
D = tf.matmul(A, B) # 计算矩阵A和B的乘积
</code></pre>
<h2 id="_3">自动求导</h2>
<h3 id="_4">一元函数求导</h3>
<p>在机器学习中，如果需要计算函数的导数，tf提供了强大的自动求导机制。以下代码展示了如何使用 <code>tf.GradientTape()</code> 计算函数 $y=x^2$ 在 $x=6$时的导数：</p>
<pre><code class="language-python">import tensorflow as tf

x = tf.Variable(initial_value=6.)
with tf.GradientTape() as tape:     # 在 tf.GradientTape() 的上下文内，所有计算步骤都会被记录以用于求导
    y = tf.square(x)
y_grad = tape.gradient(y, x)        # 计算y关于x的导数
print(y, y_grad)
</code></pre>
<p>输出：</p>
<pre><code class="language-python">tf.Tensor(9.0, shape=(), dtype=float32)
tf.Tensor(6.0, shape=(), dtype=float32)
</code></pre>
<p>这里 <code>x</code> 是一个初始化为 3 的 <strong>变量</strong> （Variable），使用 <code>tf.Variable()</code> 声明。与普通张量一样，变量同样具有形状、类型和值三种属性。使用变量需要有一个初始化过程，可以通过在 <code>tf.Variable()</code> 中指定 <code>initial_value</code> 参数来指定初始值。这里将变量 <code>x</code> 初始化为 <code>3.</code> <a href="https://tf.wiki/zh_hans/basic/basic.html#f0">1</a>。变量与普通张量的一个重要区别是其默认能够被 TensorFlow 的自动求导机制所求导，因此往往被用于定义机器学习模型的参数。</p>
<p><code>tf.GradientTape()</code> 是一个自动求导的记录器。只要进入了 <code>with tf.GradientTape() as tape</code> 的上下文环境，则在该环境中计算步骤都会被自动记录。比如在上面的示例中，计算步骤 <code>y = tf.square(x)</code> 即被自动记录。离开上下文环境后，记录将停止，但记录器 <code>tape</code> 依然可用，因此可以通过 <code>y_grad = tape.gradient(y, x)</code> 求张量 <code>y</code> 对变量 <code>x</code> 的导数。</p>
<h3 id="_5">多元函数求偏导</h3>
<p>计算函数$L(w,b)=||Xw+b-y||^2$在 $w=(1,2)^T,b=1$ 时分别对$w,b$的偏导数。其中 !$X = \begin{bmatrix} 1 &amp; 2 \ 3 &amp; 4 \end{bmatrix},  y = \begin{bmatrix} 1 \ 2\end{bmatrix}$。</p>
<pre><code class="language-python">X = tf.constant([[1., 2.], [3., 4.]])
y = tf.constant([[1.], [2.]])
w = tf.Variable(initial_value=[[1.], [2.]])
b = tf.Variable(initial_value=1.)
with tf.GradientTape() as tape:
    L = tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))
w_grad, b_grad = tape.gradient(L, [w, b])        # 计算L(w, b)关于w, b的偏导数
print(L, w_grad, b_grad)
</code></pre>
<p>输出：</p>
<pre><code class="language-python">tf.Tensor(125.0, shape=(), dtype=float32)
tf.Tensor(
[[ 70.]
[100.]], shape=(2, 1), dtype=float32)
tf.Tensor(30.0, shape=(), dtype=float32)
</code></pre>
<h2 id="_6">线性回归</h2>
<p>以下展示了如何使用 TensorFlow 计算线性回归。可以注意到，程序的结构和前述 NumPy 的实现非常类似。这里，TensorFlow 帮助我们做了两件重要的工作：</p>
<ul>
<li>使用 <code>tape.gradient(ys, xs)</code> 自动计算梯度；</li>
<li>使用 <code>optimizer.apply_gradients(grads_and_vars)</code> 自动更新模型参数。</li>
</ul>
<pre><code class="language-python">X = tf.constant(X)
y = tf.constant(y)

a = tf.Variable(initial_value=0.)
b = tf.Variable(initial_value=0.)
variables = [a, b]

num_epoch = 10000
optimizer = tf.keras.optimizers.SGD(learning_rate=5e-4)
for e in range(num_epoch):
    # 使用tf.GradientTape()记录损失函数的梯度信息
    with tf.GradientTape() as tape:
        y_pred = a * X + b
        loss = tf.reduce_sum(tf.square(y_pred - y))
    # TensorFlow自动计算损失函数关于自变量（模型参数）的梯度
    grads = tape.gradient(loss, variables)
    # TensorFlow自动根据梯度更新参数
    optimizer.apply_gradients(grads_and_vars=zip(grads, variables))
</code></pre>
<p>在这里，我们使用了前文的方式计算了损失函数关于参数的偏导数。同时，使用 <code>tf.keras.optimizers.SGD(learning_rate=5e-4)</code> 声明了一个梯度下降 <strong>优化器</strong> （Optimizer），其学习率为 5e-4。优化器可以帮助我们根据计算出的求导结果更新模型参数，从而最小化某个特定的损失函数，具体使用方式是调用其 <code>apply_gradients()</code> 方法。</p>
<p>注意到这里，更新模型参数的方法 <code>optimizer.apply_gradients()</code> 需要提供参数 <code>grads_and_vars</code>，即待更新的变量（如上述代码中的 <code>variables</code> ）及损失函数关于这些变量的偏导数（如上述代码中的 <code>grads</code> ）。具体而言，这里需要传入一个 Python 列表（List），列表中的每个元素是一个 <code>（变量的偏导数，变量）</code> 对。比如上例中需要传入的参数是 <code>[(grad_a, a), (grad_b, b)]</code> 。我们通过 <code>grads = tape.gradient(loss, variables)</code> 求出 tape 中记录的 <code>loss</code> 关于 <code>variables = [a, b]</code> 中每个变量的偏导数，也就是 <code>grads = [grad_a, grad_b]</code>，再使用 Python 的 <code>zip()</code> 函数将 <code>grads = [grad_a, grad_b]</code> 和 <code>variables = [a, b]</code> 拼装在一起，就可以组合出所需的参数了。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Do not distribute.</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>

        <div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
