# Pandas

注：文字内容大部分来自清华大学工业工程系“计算机程序设计实践”课程课件，作者为朱成礼老师。

## 1 简介

Pandas是python一个用于开放源码的数据分析扩展程序库。

Pandas的主要数据结构是Series(一维数据)和DataFrame(二维数据)，它的基础仍是numpy。

Pandas 可以从各种文件格式比如 CSV、JSON、SQL、Microsoft Excel
导入数据。并可对数据进行各种运算操作，如融合、切片、筛选、计算、统计、可视化，以及清洗和特征分析等，广泛应用于各领域的数据分析工作。

以Pycharm中的pandas库安装为例：

File\>Settings

![](media/96834e825d1b2ce95cf42d6595cc5bab.png)

在Settings中找到Python Interpreter：

![](media/eb26a0f214e0fdef5de497b593f0069b.png)

在右方的“+”处添加Pandas包即可：

![](media/59b583c7fb7efea23045c2bf6ce3f19b.png)

习惯上，在导入pandas库时，写为:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
import pandas as pd
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 2 Series对象

## 2.1创建Series对象

Series似于一维数组的对象，它只允许存放相同的数据类型的数据。它内部构件了两个相关联的数组，一个是数据数组values，一个是索引数组index。

使用Series的构造函数创建对象，语法格式：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
pandas.Series(data=None, index=None,dtype=None, name=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

data：一组数据，可以是ndarray，List，dict或一个标量。

index：数据索引标签，如果不指定，默认从 0 开始。

dtype：数据类型，默认会自己判断。

name：设置名称，为series取一个名字

创建Series对象不指定index，自动创建默认索引，也可以创建时指定索引

例2-1（自动创建默认索引）：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
scores=[95,93,92,86,90]
s1=pd.Series(scores)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

例2-2（创建时指定索引）:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
stuId = ['10106', '10242', '10107', '10230', '10153']
s2 = pd.Series(data= scores, index=stuId)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 2.2 Series对象的属性

属性 说明 语法(对象名为s)

name Series 对象及索引的name属性 s.name

shape 获取Series对象的形状，tuple s.shape

dtype Series对象中的数据类型 s.dtype

values Series对象中的数据数组 s.values

index Series对象中的索引数组 s.index

## 2.3 Series数据的查询和修改

s:

10106 95

10242 93

10107 92

10230 86

10153 90

### 2.3.1 使用索引以“Series对象[id]”或认索引来读取

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
s['10230']
s[1]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 2.3.2 使用切片方式读取多个元素

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
s[1:3]
s[s >= 93]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 2.3.3 修改或添加元素

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
s['10153'] = 100
s['10154'] = 91
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 2.4 Series对象的基本运算

适用于numpy数组的运算（+, -, \*, /）或数学函数等，也适用于Series对象。

也可以将Series对象的数据数组与标量进行+， -， \*， /等算术运算

Series对象始终保留索引和值之间的链接，在算术运算中，会自动按索引对齐，只有索引相同的元素才会进行相应的运算，索引对不上会返回数值NaN。运算后得到的是一个新的Series，原来的Series不会发生变化。

# 3 DataFrame对象

## 3.1 DataFrame对象的创建和属性查看

DataFrame是一个二维数据结构，既有行索引（index）也有列索引（columns）。
同一列的元素必须具有相同的数据类型，列与列之间可以是不同的数据类型（数值、字符串、布尔型值）。

可以看作由Series对象由一维扩展到多维。各行相同的列位置共用一个列索引，各列相同行位置共用一个行索引。

通常使用 DataFrame() 构造函数创建 DataFrame 对象，语法格式如下：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
pandas.DataFrame(data, index, columns, dtype)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

data：list 、 ndarray、 dict 、series 等

index：指定行索引，行标签，默认：arange(n)

columns：指定列索引，列标签，默认：arange(n)

dtype：指定数据类型，如果为空，自动推断类型

构建DataFrame 的方式很多，最常用的是直接传入一个由等长列表或者数组组成的字典。

例2-1:创建DataFrame对象df:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
s_data = {'StuName': ['ding', 'yan', 'feng', 'wang', 'zhang'], 'Java':[91, 90, 86, 91, 92], 'Python': [95, 93, 92, 86, 90]}
df=pd.DataFrame(s_data)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

例2-2:指定DataFrame对象的行索引、列索引

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.index = ['10001', '10002', '10003', '10004', '10005']
df.columns = ['StuName', 'Java', 'Python']
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

DataFrame对象的常用属性:

T 行列转置

columns 查看列索引，可以直接通过赋值改变列索引

index 查看行索引，也可以通过赋值改变行索引

dtypes 查看各列的数据类型（各列类型可能不一样，返回的是Series）

shape 查看DataFrame的形状，是包含两个整数元素的元组

ndim 维度，2

size 返回DataFrame对象的元素个数，行与列的乘积

values 返回存储在DataFrame对象中的数据，是一个数组

## 3.2 DataFrame数据的查询和编辑

例2-3：

df:

StuName Java Python

10001 ding 91 95

10002 yan 90 93

10003 feng 86 92

10004 wang 91 86

10005 zhang 92 90

可直接按列和行索引名获取元素:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df[‘Java’][‘10002’]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 3.2.1 选取列

选取列数据:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.Java 
df[‘Java’]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

选取多列数据:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df[[‘StuName’,’Python’]]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

布尔选择:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df[df[‘Python’]=90]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 3.2.2 选取行

行切片:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df[start:stop:step]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

布尔选择:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df[df[‘Java’]>90]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

使用query函数按筛选条件获取行:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.query("Python>90 and Java>90")
df.query('Python==[90, 92]')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

使用DataFrame特殊函数获取行:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
head(n) #前n行
tail(n) #后n行
sample(n) #随机抽取n行
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 3.2.3 选取行和列

使用loc和iloc方法获得行:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.loc[['10106', '10242'], 'Java']
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

选取行和列:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.iloc[0 : 2 , 1]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 3.2.4 判断元素是否在某个列表中

isin函数：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.isin(['Java', 95])
df[df.isin(['Java', 95])] #得到二维数组
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 3.2.5 编辑DataFrame

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.drop('Java', axis=1, inplace=True)
axis=1 # 删除行 
axis=0 # 删除列
df['C++'] = 100 # 添加一列
df['C++'] = [77, 83, 90, 91, 76] # 修改一列
df.iloc[1,1] = 100  # 修改单个元素
df.loc['10106','C++'] = 100 # 修改单个元素
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 4 DataFrame数据运算

## 4.1 DataFrame算术运算与排序

### 4.1.1 算术运算

DataFrame对象在进行算术运算时，将两个对象的行名（行索引）、列名（列索引）都相同的元素进行运算，其他位置的元素则用NaN填充。

DataFrame对象各列元素数据类型不一定相同，如果对应元素之间不能进行数学运算，运行出错

apply()函数将运算函数套用到DataFrame的行或列上，applymap()函数将运算函数应用到DataFrame的每个元素上。

例：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def func_avg(x):
return x.sum() / len(x)  # 将函数应用于列，求列平均值
df_avg = df.apply(func_avg, axis=0)
print(df_avg)
def func_sqrt(x):
return np.sqrt(x) * 10

df_sqrt = df.applymap(func_sqrt)
print(df_sqrt)  # 将函数应用于df各个元素上
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

### 4.1.2 排序

按行索引或列索引排序

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.sort_index(axis=0, ascending=True)
#  axis=0行排序，axis=1列排序 ascending=True升序，False降序
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

按指定列或行的值进行排序

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.sort_values(by, axis=0, ascending=True)
#  by，指定某些行或列为排序依据，axis=0行排序，axis=1列排序ascending，
#  True升序，False降序
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

沿着行或计算元素的排名，返回名次

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.rank(axis=0, method='average', ascending=True)
#  method，average值相等的元素平分名次，min就低， max就高，first按出现的#  顺序分配排名。
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 4.2 DataFrame数学统计

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.count(axis=0) # 统计每列数值型的元素个数。
df.mean(axis=None, skipna=None) # 返回指定轴上元素值的平均值。
df.min(axis=0) # 返回每列（行）的最小值。
df.max(axis=0) # 返回每列（行）的最大值
df.median(axis=None, skipna=None) # 返回指定轴上元素值的中位数,axis=0表
#示按列统计，axis=1表示按行统计skipna=None，默认True跳过NaN值。
df.sum(axis=None,skipna=None) # 返回指定轴上元素值的和
df.var(axis=None, skipna=None) # 返回指定轴上元素值的均方差
df.std(axis=None, skipna=None) # 返回指定轴上元素值的标准差
df.cov() # 计算df的列列之间的协方差，不包括NA/空值。
df.corr(method='pearson') # 计算df的列列之间的相关性，不包括NA/空值
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 5 Pandas数据可视化

Pandas集成了Matplotlib中的基础组件，自带绘图功能，调用DataFame对象的plot函数可以快速地把DataFrame中的数据绘制成各种类型的图。

语法格式：df.plot(x=…,y=…,kind=…,…)

xlabel:设置x轴标签

ylabel:设置y轴标签

kind: 所要绘制的图类型

kind='line'，绘制折线图;kind='bar'，绘制条形图；

kind='barh'，绘制横向条形图；kind='hist'，绘制直方图（柱状图）；kind='box'，绘制箱线图；kind='kde'，绘制Kernel的密度估计图，主要对柱状图添加Kernel概率密度线；

kind='density'，绘制的图与kind='kde'的图相同；kind='area'，绘制区域图；

kind='pie'，绘制饼图；kind='scatter'，绘制散点图。

figsize:图片尺寸大小

use_index:默认用索引做x轴

title:图片的标题

grid:图片是否有网格

legend:子图的图例

style:折线图的线型

xticks:x轴刻度值，序列形式

yticks:y轴刻度值，序列形式

xlim:x坐标轴的范围,列表或元组形式

ylim:y坐标轴的范围，列表或元组形式

fontsize:设置轴刻度的字体大小

alpha:设置图表填充的不透明度

绘制之后，保存图片：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.savefig('figname.png')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

在运行程序时显示保存的图片：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

下面以一些示例说明如何画具体的图：

## 5.1 绘制折线图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df=pd.read_csv('data/GDP_2001_2019.csv',index_col=[0],header=[0])
years = [2001, 2005, 2010, 2015, 2020]
GDP = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22]
df.plot(kind='line’,xticks=years,yticks=GDP,grid=True,xlabel='年份', ylabel='GDP(万亿)', title='主要国家GDP(2001-2019)', style='1--')
plt.savefig('figures/GDP_2001_2009.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

![](media/6f4f29071883de9a96147b4ab2a29f21.png)

（标题中的“GPD”应为GDP，系原作者笔误）

## 5.2 绘制条形图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
countries = ['中国', '美国', '俄罗斯', '法国', '英国']
items = ['GDP（万亿美元）', '人口（亿）']
df = pd.read_csv('data/GDP_Pop_2019.csv',index_col=[0], usecols=['Country', 'GDP', 'Pop'])
df.index = countries
df.columns = items
df.plot(kind='bar', title='2019年GDP/人口', style='2-', grid=True, rot=0)
plt.savefig('figures/GDP_2009_1.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

![](media/de60c38b8eaeaef840441addad2e2969.png)

（标题中的“GPD”应为GDP，系原作者笔误）

## 5.3 绘制直方图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
columns = ['花萼长', '花萼宽', '花瓣长', '花瓣宽']
df = pd.read_csv('data/iris_hist.csv', header=None)
df.columns = columns
print(df)
df.hist(bins=20)
plt.savefig('figures/iris_hist.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

![](media/a68adfc417f0b1e2bf9877ab02f4016c.png)

## 5.4 绘制箱线图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
matplotlib.rcParams['font.family'] = 'STSong'
matplotlib.rcParams['font.size'] = 12
columns = ['花萼长', '花萼宽', '花瓣长', '花瓣宽']
df = pd.read_csv('data/iris_hist.csv', header=None)
df.columns = columns
df.plot(kind='box')
plt.savefig('figures/iris_box.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 5.5 绘制散点图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df = pd.read_csv('data/iris_hist.csv', header=None)
df.columns = ['花萼长', '花萼宽', '花瓣长', '花瓣宽']
df.plot(x='花萼长', y='花萼宽', kind='scatter', style='+')
plt.savefig('figures/iris_scatter1.png')
plt.show()
df.plot(x='花瓣长', y='花瓣宽', kind='scatter', style='o')
plt.savefig('figures/iris_scatter2.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

![](media/75bf688b14d9bf170a67de1dc8287c1d.png)![](media/2889628e804d997af7df145eec4077eb.png)

## 5.6 绘制饼图

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
countries = ['中国', '美国', '俄罗斯', '法国', '英国', '其他']
df = pd.read_csv('data/GDP_2019.csv', index_col=[0], header=[0])
df.index = countries
print(df)
df['GDP'].plot(kind='pie', subplots=True, autopct='%2.2f%%', legend=False, ylabel='', title='五国GDP占比')
plt.savefig('figures/GDP_2019_pie.png')
plt.show()
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

![](media/f110ad109ab07c846411ad39d0066f5e.png)

# 6 Pandas读写数据

Pandas提供了常用数据文件的读写函数：

read_csv():读取csv格式的数据

to_csv():写入csv格式的数据

read_table():读取普通分隔符分割的数据

read_excel():读取excel格式的数据

to_excel():写入excel格式的数据

## 6.1 读写csv和文本文件

### 6.1.1 使用pandas对象的read_csv函数读取文件：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
pd.read_csv(filepath,sep=',',header='infer',names=None, index_col=None, usecols=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明：

filepath:文件路径，可以是本地文件，也可以是http文件

sep:指定分隔符，默认为：,

header:指定第几行为列名，默认0（第一行），如果没有列名，可以设置为None

names:重设表头，即列名

index_col:指定行索引名，可以是列编号或列名

usecols:用于选取某些列，其他的列会被忽略

### 6.1.2 使用DataFrame对象的to_csv函数写入csv文件：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.to_csv(filepath, sep=',', na_rep='', columns=None,
header=True, index=True)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明：

filepath:写入的文件名或对象

sep:数据分隔符

na_rep:把空字段指定为na_rep指定的值

columns:指定要写入文件包含哪些列

header:是否保存列名

index:是否保存行索引

## 6.2 读写Excel数据文件

### 6.2.1 读取excel数据：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
pandas.read_excel( io, sheet_name=0, header=0, index_col=None, usercols=None,skiprows=None, skip_footer=0)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明：

io:excel文件名

sheetname:指sheet表名或索引值，可以使用列表

header:指定作为列名的行

index_col:指定某列为行索引，可以是列编号或列名

usecols:指定要加载的列

skiprows:指定要排除的行

skip_footer:读取数据时忽略最后skip_footer指定的行

### 6.2.2 写入excel数据：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.to_excel(excel_writer, na_rep=’’, columns=None,
header=True, index=True)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明：

excel_writer:写入的excel文件

na_rep:缺失值填充

columns:选择输出的列

header:指定列名，布尔值或者列表

index:是否显示行索引

# 7 Pandas数据分析——数据预处理

在数据分析之前须对数据进行预处理，处理数据中的“脏数据”，提高数据分析的准确性和有效性。脏数据主要表现为数据缺失、数据重复、数据错误等。

数据预处理主要任务：数据探索分析、重复行分析与处理、缺失值分析与处理、异常值分析与处理。

## 7.1 数据探索分析

data_1=pd.read_csv(…)

data_1.info():查看数据集信息，包括列数、列名、非空列数、数据类型等

data_1.head():显示前五行数据

data_1.describe():描述统计性信息

## 7.2 重复行分析与处理

处理重复行的函数：

df.duplicated(subset=None, keep='first'):

针对由subset指定的某些列，返回用布尔序列表示的重复行标

记。

（keep设为first表示第一次出现不标记重复，last表示最后

一次出现不标记重复，False表示都标记重复）

df.drop_duplicates(subset=None, keep='first', inplace=False):

用于删除df中的重复行，并返回删除重复行后的结果。

（inplace=False表示返回副本，True在原数据上执行。 ）

df.index.duplicated(keep='first', inplace=False):

根据索引标记重复行

## 7.3 缺失值分析与处理

缺失值的处理方法有：

删除含有缺失值的记录

数据补齐（就近补齐、均值补齐、利用同类均值补齐、拟合补齐等）

也可以不处理

### 7.3.1 DataFrame对象缺失值检测函数

df.isnull():检查df对象中的缺失值，返回矩阵。是缺失值在相应位置标记True，否则标记False。

df.isnull().any():默认检查df对象中的各列是否存在缺失值，any(1)检测各行，返回以列名或行索引为索引的Series，有缺失值的列、行对应值为True，否则为False。

df.isnull().all():默认检查各行是否全为缺失值，用法与any()类似。

df.isnull().sum():统计缺失值的个数。

### 7.3.2 缺失值处理函数

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.fillna(value=None,method=None,axis=None,inplace=True,limit=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明：

value:用于填充的值

method:当没有指定value参数时，可以以该参数的内置方式填充缺失值，bfill用下一个非缺失值填充，ffill用上一个非缺失值填充。常与axis一起使用，指定填充维度。method参数不能与value同时出现。

axis:填充维度。0指行维度，1指列维度。

inplace:是否修改原对象的值，True表示修改，False表示创建一个副本，原对象不变。

limit:指定填充的个数上限，默认为None，即不限制。

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df.dropna(axis=0,how=’any’,thresh=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

参数说明（举例）：

df1 = df.dropna(axis=1) 删除含有缺失值的列

df2 = df.dropna(how='all')
删除全为缺失值的行，若为any，则是删除含有至少一个缺失值的行

df3 = df.dropna(thresh=2) 删除至少含有2个缺失值的行

## 7.4 异常值分析与处理

### 7.4.1 基于偏差的方法

对服从正态分布的数据，异常值被定义为与平均值的偏差超过三倍标准差（3σ）的值。

### 7.4.2 箱线图分析法

箱线图，又称盒状图，是一种显示一组数据分散情况的统计图，因形状如箱子而得名。

异常值定义为：

小于QL-1.5IQR，或大于QU+1.5IQR。其中，QL为下四分位数，QU为上四分位数，IQR=QU-QL称为四分位数间距。

删除异常值示例:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
sw_q1 = df_data.quantile(0.25) # 计算上四分位
sw_q3 = df_data['SepalWidth'].quantile(0.75) # 计算下四分位
sw_iqr = sw_q3 - sw_q1 # 计算四分位间距
sw_low = sw_q1 - 1.5 * sw_iqr # 计算下限
sw_up = sw_q3 + 1.5 * sw_iqr # 计算上限

delabnormal_data = df_data[(df_data > sw_low) & (df_data < sw_up)]
# 删除异常值（保留正常值）
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 8 Pandas数据分析——数据特征分析

## 8.1 分布分析

分布分析用来揭示数据的分布特征和分布类型，显示其分布情况；面对大量的数据，可使用直方图图像来描述数据的分布情况。

## 8.2 相关性分析

相关分析是研究两个或两个以上的变量间的相关关系的统计分析方法。

相关系数是变量间关联程度的最基本的度量方法。

pandas中可采用corr()函数计算各变量间的相关性。

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
corr_matrix = df_data.corr(method='pearson')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 8.3 特征选择

当数据预处理完成后，需要选择有意义的特征来构建数据分析模型，好的特征能够构造出较好的分析模型。

特征选择主要有两个目的：

（1）减少特征数量、降维，使模型泛化能力更强，减少过拟合

（2）增强对特征和特征值之间的理解

可以根据相关性分析得出的相关性矩阵，利用query函数来筛选行、列索引：

如筛选与column1相关系数大于0.7或小于-0.7的列：

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
corr_select = corr_matrix.query('column1 > 0.7 | column1 < -0.7')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# 9 Pandas数据分析——建模分析方法

需要调用的库有：

import pandas as pd

from sklearn.model_selection import train_test_split

from sklearn.tree import DecisionTreeClassifier （决策树分类）

from sklearn.linear_model import LogisticRegression（逻辑回归）

from sklearn import metrics

## 9.1 分类分析方法

决策树分类：

属性集为x，分类标号为y

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#将数据集分成训练集和测试集：
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
# test_size为测试集划分比例
# 建立决策树模型：
model_dtc=DecisionTreeClassifier()
# 训练模型：
model_dtc.fit(x_train,y_train)
# 测试模型：
y_pred=model_dtc.predict(x_test)
# 得出决策树分类模型的准确率：
model_dtc.score(x_test,y_test)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

## 9.2 回归分析方法

逻辑回归模型：

特征列为x，预测值列为y

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# 将数据集分成训练集和测试集：
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
# test_size为测试集划分比例
# 建立逻辑回归模型：
model_lr = LogisticRegression(max_iter=500)
model_lr.fit(x_train, y_train)
# 预测测试集：
y_pred = model_lr.predict(x_test)
# 得出逻辑回归模型评分：
model_lr.score(x_test,y_test)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
